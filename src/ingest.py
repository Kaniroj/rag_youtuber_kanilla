from __future__ import annotations

import textwrap
import uuid
from pathlib import Path
from typing import Iterable, List

import google.generativeai as genai
import lancedb
import numpy as np
import pandas as pd

from src.config import settings


# ---------- Ù…Ø±Ø­Ù„Ù‡ Û±: Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Gemini Ø¨Ø±Ø§ÛŒ embedding ----------

def configure_gemini() -> None:
    """ØªÙ†Ø¸ÛŒÙ… API key Ø¨Ø±Ø§ÛŒ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÛŒ Gemini."""
    genai.configure(api_key=settings.gemini_api_key)


def get_embedding(text: str) -> List[float]:
    """
    Ú¯Ø±ÙØªÙ† embedding Ø§Ø² ÛŒÚ© Ù…ØªÙ†.
    Ø§Ø² Ù…Ø¯Ù„ embedding Ø±Ø³Ù…ÛŒ Gemini Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….
    """
    # Ø¨Ø±Ø§ÛŒ Ø§Ø­ØªÛŒØ§Ø·ØŒ Ù…ØªÙ† Ø®ÛŒÙ„ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø±Ø§ Ú©ÙˆØªØ§Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    clipped = textwrap.shorten(text, width=8000, placeholder=" ...")

    result = genai.embed_content(
        model="models/text-embedding-004",  # Ù…Ø¯Ù„ embedding Gemini
        content=clipped,
    )
    embedding = result["embedding"]
    # Ù…Ø·Ù…Ø¦Ù† Ø´Ùˆ Ù„ÛŒØ³Øª float Ø§Ø³Øª (Ù†Ù‡ numpy array Ø¹Ø¬ÛŒØ¨)
    return list(embedding)


# ---------- Ù…Ø±Ø­Ù„Ù‡ Û²: Ø®ÙˆØ§Ù†Ø¯Ù† Ùˆ Ú†Ø§Ù†Ú©â€ŒÚ©Ø±Ø¯Ù† ØªØ±Ù†Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§ ----------

def load_transcript_files() -> Iterable[Path]:
    """
    Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØªØ±Ù†Ø³Ú©Ø±ÛŒÙ¾Øª Ø±Ø§ Ø§Ø² Ù¾ÙˆØ´Ù‡â€ŒÛŒ ØªÙ†Ø¸ÛŒÙ…â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
    ÙØ¹Ù„Ø§Ù‹ Ù¾Ø³ÙˆÙ†Ø¯Ù‡Ø§ÛŒ txt Ùˆ md Ø±Ø§ Ø¯Ø± Ù†Ø¸Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ….
    """
    transcripts_dir = settings.transcripts_dir
    if not transcripts_dir.exists():
        raise FileNotFoundError(f"Transcript directory not found: {transcripts_dir}")

    for path in transcripts_dir.iterdir():
        if path.is_file() and path.suffix.lower() in {".txt", ".md"}:
            yield path


def read_text_file(path: Path) -> str:
    """Ø®ÙˆØ§Ù†Ø¯Ù† Ù…Ø­ØªÙˆØ§ÛŒ ÛŒÚ© ÙØ§ÛŒÙ„ Ù…ØªÙ†ÛŒ Ø¨Ø§ utf-8."""
    return path.read_text(encoding="utf-8")


def chunk_text(text: str, chunk_size: int = 800, overlap: int = 200) -> List[str]:
    """
    Ø´Ú©Ø³ØªÙ† Ù…ØªÙ† Ø¨Ù„Ù†Ø¯ Ø¨Ù‡ Ú†Ø§Ù†Ú©â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©ØªØ± Ø¨Ø±Ø§ÛŒ RAG.

    Ù…Ø«Ø§Ù„: chunk_size=800, overlap=200 ÛŒØ¹Ù†ÛŒ:
    Ú†Ø§Ù†Ú© Û°: Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ 0-800
    Ú†Ø§Ù†Ú© Û±: Ø§Ø² 600 ØªØ§ 1400
    Ùˆ ...

    Ø§ÛŒÙ† Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯ context Ø¯Ø± Ù…Ø±Ø² Ú†Ø§Ù†Ú©â€ŒÙ‡Ø§ Ú¯Ù… Ù†Ø´ÙˆØ¯.
    """
    if not text:
        return []

    # whitespaceÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ø±Ø§ ØªÙ…ÛŒØ² Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    text = " ".join(text.split())

    chunks: List[str] = []
    start = 0
    length = len(text)

    while start < length:
        end = min(start + chunk_size, length)
        chunk = text[start:end]
        chunks.append(chunk)
        if end == length:
            break
        start = end - overlap

    return chunks


# ---------- Ù…Ø±Ø­Ù„Ù‡ Û³: Ø³Ø§Ø®Øª Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ LanceDB ----------

def build_segments_dataframe() -> pd.DataFrame:
    """
    ØªØ±Ù†Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§ Ø±Ø§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯ØŒ Ú†Ø§Ù†Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ
    ÛŒÚ© DataFrame Ø¨Ø§ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ù…ÛŒâ€ŒØ³Ø§Ø²Ø¯:

    - id: str (uuid)
    - video_id: str (Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø¨Ø¯ÙˆÙ† Ù¾Ø³ÙˆÙ†Ø¯)
    - chunk_index: int
    - text: str
    - embedding: list[float]
    """
    configure_gemini()

    rows = []

    for transcript_path in load_transcript_files():
        video_id = transcript_path.stem  # Ø§Ø³Ù… ÙØ§ÛŒÙ„ Ø¨Ø¯ÙˆÙ† Ù¾Ø³ÙˆÙ†Ø¯
        raw_text = read_text_file(transcript_path)
        chunks = chunk_text(raw_text)

        for idx, chunk in enumerate(chunks):
            emb = get_embedding(chunk)
            rows.append(
                {
                    "id": str(uuid.uuid4()),
                    "video_id": video_id,
                    "chunk_index": idx,
                    "text": chunk,
                    "embedding": emb,
                }
            )

    if not rows:
        raise RuntimeError(
            "Ù‡ÛŒÚ† Ø¯ÛŒØªØ§ÛŒÛŒ Ø®ÙˆØ§Ù†Ø¯Ù‡ Ù†Ø´Ø¯. Ù…Ø·Ù…Ø¦Ù† Ø´Ùˆ Ø¯Ø± data/transcripts ÙØ§ÛŒÙ„ .txt ÛŒØ§ .md Ø¯Ø§Ø±ÛŒ."
        )

    df = pd.DataFrame(rows)
    return df


# ---------- Ù…Ø±Ø­Ù„Ù‡ Û´: Ù†ÙˆØ´ØªÙ† Ø¯Ø± LanceDB ----------

def create_or_overwrite_lancedb_table(df: pd.DataFrame) -> None:
    """
    Ø¯ÛŒØªØ§Ø¨ÛŒØ³ LanceDB Ø±Ø§ Ø¯Ø± Ù…Ø³ÛŒØ± ØªÙ†Ø¸ÛŒÙ…â€ŒØ´Ø¯Ù‡ Ù…ÛŒâ€ŒØ³Ø§Ø²Ø¯
    Ùˆ Ø¬Ø¯ÙˆÙ„ 'segments' Ø±Ø§ overwrite Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    db_path = settings.lancedb_dir
    db_path.mkdir(parents=True, exist_ok=True)

    db = lancedb.connect(str(db_path))

    table_name = settings.lancedb_table

    # Ø§Ú¯Ø± Ø¬Ø¯ÙˆÙ„ Ø§Ø² Ù‚Ø¨Ù„ Ù‡Ø³ØªØŒ Ø­Ø°Ù Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… (Ø­Ø§Ù„Øª Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡)
    if table_name in db.table_names():
        db.drop_table(table_name)

    # LanceDB schema Ø±Ø§ Ø§Ø² Ø±ÙˆÛŒ DataFrame ØªØ´Ø®ÛŒØµ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯
    db.create_table(table_name, data=df)
    print(f"âœ… LanceDB table '{table_name}' created with {len(df)} rows at {db_path}")


def main() -> None:
    print("ğŸš€ Ø´Ø±ÙˆØ¹ ingestion ØªØ±Ù†Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§...")
    df = build_segments_dataframe()
    print(f"âœ… DataFrame Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯ØŒ ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§: {len(df)}")
    create_or_overwrite_lancedb_table(df)
    print("ğŸ‰ Ú©Ø§Ø± ingestion Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÙ…Ø§Ù… Ø´Ø¯.")


if __name__ == "__main__":
    main()
